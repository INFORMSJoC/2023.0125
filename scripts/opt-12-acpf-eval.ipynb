{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a92888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import hashlib\n",
    "import json\n",
    "import logging\n",
    "import math\n",
    "import multiprocessing\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import yaml\n",
    "from egret.data.model_data import ModelData\n",
    "from egret.models.acopf import create_psv_acopf_model\n",
    "from pyomo.environ import Constraint, Var, minimize, value\n",
    "from pyomo.opt import SolverFactory\n",
    "\n",
    "from config import (SP_RESULTS_DIR, RO_RESULTS_DIR,\n",
    "                    SPECS_COMPLETE_YAMLS, ACPF_RESULTS_DIR)\n",
    "from model import DC, LPAC, Solution\n",
    "from util import in_notebook, PyomoSolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962be04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger('pyomo.core').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1483cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashfilename(tup):\n",
    "    return hashlib.md5(str(tup).encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faceeb92-9d18-4d2c-a9e4-7975f4ad04b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_md_inplace_dc(md, omega, sol, specs):\n",
    "\n",
    "    for n in specs['N']:\n",
    "        bus_dict[n].update({\n",
    "            'vm': 1.0,\n",
    "            'va': sol['theta'][n, omega] * 180 / math.pi\n",
    "        })\n",
    "\n",
    "    for n in specs['N']:\n",
    "        for d in specs['D_n'].get(n, list()):\n",
    "            load_dict[d].update({\n",
    "                'in_service': True,\n",
    "                'p_load_shed': specs['p_load_hi'][d] * (1 - sol['z'][d, omega]) * md.data['system']['baseMVA'],\n",
    "                'q_load_shed': specs['q_load_hi'][d] * (1 - sol['z'][d, omega]) * md.data['system']['baseMVA'],\n",
    "            })\n",
    "\n",
    "    for n in specs['N']:\n",
    "        for g in specs['G_n'].get(n, list()):\n",
    "            generator_dict[g].update({\n",
    "                'in_service': bool(sol['alpha'][n, omega]),\n",
    "                'pg': sol['p_hat'][g, omega] * md.data['system']['baseMVA'],\n",
    "                'qg': 0.0,\n",
    "                'p_over_generation': sol['p_check'][g, omega] * md.data['system']['baseMVA'],\n",
    "                'q_over_generation': 0.0,\n",
    "            })\n",
    "\n",
    "    for (n, m) in specs['E']:\n",
    "        for l in specs['L_nm'][n, m]:\n",
    "            branch_dict[l].update({\n",
    "                'in_service': bool(sol['beta'][n, m, omega]),\n",
    "                'pf': sol['p_tilde'][l, omega] * md.data['system']['baseMVA'],\n",
    "                'qf': 0.0,\n",
    "                'pt': -sol['p_tilde'][l, omega] * md.data['system']['baseMVA'],\n",
    "                'qt': 0.0,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343cd630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_md_inplace_lpac(md, omega, sol, specs):\n",
    "    \n",
    "    for n in specs['N']:\n",
    "        bus_dict[n].update({\n",
    "            'vm': specs['v'][n] + sol['phi'][n, omega],\n",
    "            'va': sol['theta'][n, omega] * 180 / math.pi,\n",
    "        })\n",
    "\n",
    "    for n in specs['N']:\n",
    "        for d in specs['D_n'].get(n, list()):\n",
    "            load_dict[d].update({\n",
    "                'in_service': True,\n",
    "                'p_load_shed': specs['p_load_hi'][d] * (1 - sol['z'][d, omega]) * md.data['system']['baseMVA'],\n",
    "                'q_load_shed': specs['q_load_hi'][d] * (1 - sol['z'][d, omega]) * md.data['system']['baseMVA'],\n",
    "            })\n",
    "\n",
    "    for n in specs['N']:\n",
    "        for g in specs['G_n'].get(n, list()):\n",
    "            generator_dict[g].update({\n",
    "                'in_service': bool(sol['alpha'][n, omega]),\n",
    "                'pg': sol['p_hat'][g, omega] * md.data['system']['baseMVA'],\n",
    "                'qg': sol['q_hat'][g, omega] * md.data['system']['baseMVA'],\n",
    "                'p_over_generation': sol['p_check'][g, omega] * md.data['system']['baseMVA'],\n",
    "                'q_over_generation': 0 * md.data['system']['baseMVA'],\n",
    "            })\n",
    "\n",
    "    for (n, m) in specs['E']:\n",
    "        for l in specs['L_nm'][n, m]:\n",
    "            branch_dict[l].update({\n",
    "                'in_service': bool(sol['beta'][n, m, omega]),\n",
    "                'pf': sol['p_tilde'][l, 'f', omega] * md.data['system']['baseMVA'],\n",
    "                'qf': sol['q_tilde'][l, 'f', omega] * md.data['system']['baseMVA'],\n",
    "                'pt': sol['p_tilde'][l, 'b', omega] * md.data['system']['baseMVA'],\n",
    "                'qt': sol['q_tilde'][l, 'b', omega] * md.data['system']['baseMVA'],\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb720b8b-6f26-414b-ab2f-3afbfe4cca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_sol_keys = ['p_hat', 'p_check', 'p_tilde', 'z', 'theta', 'sin_hat', 'alpha', 'beta',\n",
    "               'gamma_over', 'gamma_under', 'gamma']\n",
    "lpac_sol_keys = ['p_hat', 'q_hat', 'p_check', 'p_tilde', 'q_tilde',\n",
    "                 'z', 'theta', 'phi', 'sin_hat', 'cos_hat', 'alpha', 'beta',\n",
    "                 'gamma_over', 'gamma_under', 'gamma']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cff18e1",
   "metadata": {},
   "source": [
    "# User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d0fe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if in_notebook():\n",
    "    f = 0\n",
    "    r_hat = 3\n",
    "    casestudy = 'imelda'\n",
    "    pftype = 'dc'\n",
    "    approach = 'stochastic'\n",
    "else:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--f')\n",
    "    parser.add_argument('--rhat')\n",
    "    parser.add_argument('--casestudy')\n",
    "    parser.add_argument('--pftype')\n",
    "    parser.add_argument('--approach')\n",
    "    args = parser.parse_args()\n",
    "    f = int(args.f)\n",
    "    r_hat = int(args.rhat)\n",
    "    pftype = str(args.pftype)\n",
    "    casestudy = str(args.casestudy)\n",
    "    approach = str(args.approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adcb94d-9b20-472b-a55d-9867ebab5d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if approach == 'stochastic':\n",
    "    MY_RESULTS_DIR = SP_RESULTS_DIR\n",
    "elif approach == 'robust':\n",
    "    MY_RESULTS_DIR = RO_RESULTS_DIR\n",
    "else:\n",
    "    raise ValueError('`approach` must be either \"stochastic\" or \"robust\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c00cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SPECS_COMPLETE_YAMLS[casestudy, pftype]) as fh:\n",
    "    specs = yaml.load(fh, Loader=yaml.Loader)\n",
    "    specs['options']['approach'] = 'stochastic'\n",
    "    for key, val in specs['r_hat'].items():\n",
    "        specs['r_hat'][key] = min(val, r_hat)\n",
    "    for key in list(specs['xi']):\n",
    "        (k, r, omega) = key\n",
    "        if r > r_hat:\n",
    "            specs['xi'].pop(key)\n",
    "    for k in specs['R']:\n",
    "        specs['R'][k] = [i for i in range(1, min(max(specs['R'][k]), r_hat) + 1)]\n",
    "    \n",
    "# instantiate a model\n",
    "if pftype in ['dc']:\n",
    "    MODEL = DC(**specs)\n",
    "\n",
    "elif pftype in ['lpacc', 'lpacf', 'qpac']:\n",
    "    MODEL = LPAC(**specs)\n",
    "\n",
    "# budget constraint\n",
    "MODEL.con_resource_hi.RHS = f\n",
    "\n",
    "# update\n",
    "MODEL.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be17f39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the identified optimal solution\n",
    "zipfile = os.path.join(MY_RESULTS_DIR, f'{casestudy}-{pftype}-f{f}-r{r_hat}.zip')\n",
    "sol_part = Solution.from_zip(zipfile)\n",
    "\n",
    "# fix identified optimal solution\n",
    "for (k, r), val in sol_part['x'].round().items():\n",
    "    if val > 0.5:\n",
    "        MODEL.x[k, r].lb = MODEL.x[k, r].ub = 1\n",
    "    else:\n",
    "        MODEL.x[k, r].lb = MODEL.x[k, r].ub = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52492a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve the model\n",
    "MODEL.model.setParam('OutputFlag', 0)\n",
    "MODEL.model.setParam('MIPGap', 0.00)\n",
    "MODEL.model.setParam('Threads', np.floor(multiprocessing.cpu_count()))\n",
    "MODEL.model.setParam('ImpliedCuts', 2)\n",
    "MODEL.model.setParam('PreSolve', 2)\n",
    "MODEL.model.setParam('CutPasses', 10)\n",
    "MODEL.model.setParam('MIPFocus', 2)\n",
    "MODEL.update()\n",
    "MODEL.solve()\n",
    "\n",
    "# store the object\n",
    "sol_full = Solution.from_solved_instance(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96539bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ModelData()\n",
    "\n",
    "md.data['system']['model_name'] = 'ACTIVSg2000reduced663'\n",
    "md.data['system']['mpc-version'] = '2'\n",
    "md.data['system']['baseMVA'] = 100.0\n",
    "md.data['system']['reference_bus'] = specs['n_ref']\n",
    "md.data['system']['reference_bus_angle'] = 0\n",
    "\n",
    "bus_dict = dict()\n",
    "load_dict = dict()\n",
    "generator_dict = dict()\n",
    "branch_dict = dict()\n",
    "\n",
    "for n in specs['N']:\n",
    "    bus_dict[n] = {\n",
    "        'v_min': specs['v_lo'][n],\n",
    "        'v_max': specs['v_hi'][n],\n",
    "    }\n",
    "\n",
    "for n in specs['N']:\n",
    "    for d in specs['D_n'].get(n, list()):\n",
    "        load_dict[d] = {\n",
    "            'p_load': specs['p_load_hi'][d] * md.data['system']['baseMVA'],\n",
    "            'q_load': specs['q_load_hi'][d] * md.data['system']['baseMVA'],\n",
    "            'bus': n,\n",
    "        }\n",
    "\n",
    "for n in specs['N']:\n",
    "    for g in specs['G_n'].get(n, list()):\n",
    "        generator_dict[g] = {\n",
    "            'p_min': specs['p_gen_lo'][g] * md.data['system']['baseMVA'],\n",
    "            'p_max': specs['p_gen_hi'][g] * md.data['system']['baseMVA'],\n",
    "            'q_min': specs['q_gen_lo'][g] * md.data['system']['baseMVA'],\n",
    "            'q_max': specs['q_gen_hi'][g] * md.data['system']['baseMVA'],\n",
    "            'p_cost': {'data_type': 'cost_curve', 'cost_curve_type': 'polynomial', 'values': {0: 0, 1: 1e6}},\n",
    "            'bus': n,\n",
    "        }\n",
    "\n",
    "for (n, m) in specs['E']:\n",
    "    for l in specs['L_nm'][n, m]:\n",
    "        y = complex(specs['g'][l], specs['b'][l])\n",
    "        z = 1 / y\n",
    "        r, x = z.real, z.imag\n",
    "        branch_dict[l] = {\n",
    "            'from_bus': n,\n",
    "            'to_bus': m,\n",
    "            'resistance': r,\n",
    "            'reactance': x,\n",
    "            'charging_susceptance': 0,\n",
    "            'branch_type': 'line',\n",
    "            'rating_long_term': specs['s_flow_hi'][l] * md.data['system']['baseMVA'],\n",
    "            'angle_diff_min': -specs['options']['theta_delta_max'] * 180 / math.pi,\n",
    "            'angle_diff_max': specs['options']['theta_delta_max'] * 180 / math.pi,\n",
    "        }\n",
    "\n",
    "md.data['elements']['bus'] = bus_dict        \n",
    "md.data['elements']['load'] = load_dict\n",
    "md.data['elements']['generator'] = generator_dict\n",
    "md.data['elements']['branch'] = branch_dict\n",
    "\n",
    "md.data['system']['load_mismatch_cost'] = 0\n",
    "md.data['system']['q_load_mismatch_cost'] = 0\n",
    "\n",
    "kwargs = {'include_feasibility_slack': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffb5038",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashdict = dict()\n",
    "\n",
    "for omega in MODEL.Omega:\n",
    "\n",
    "    tup = tuple(sorted(sol_full['alpha'].loc[sol_full['alpha'].lt(0.5)].loc[slice(None), omega].index))\n",
    "    hashtup = hashfilename(tup)\n",
    "    os.makedirs(os.path.join(ACPF_RESULTS_DIR, pftype), exist_ok=True)\n",
    "    sur_filename = os.path.join(ACPF_RESULTS_DIR, pftype, f'{hashtup}-{pftype}.zip')\n",
    "    val_filename = os.path.join(ACPF_RESULTS_DIR, pftype, f'{hashtup}-ac.zip')\n",
    "\n",
    "    # if the contingency has not yet been assessed under the surrogate PF model\n",
    "    if not os.path.exists(sur_filename):\n",
    "        sol_full_omega = Solution.from_solved_instance(MODEL)\n",
    "        for key in sol_full.keys():\n",
    "            if pftype in ['dc'] and key in dc_sol_keys:\n",
    "                tmp = sol_full_omega[key]\n",
    "                tmp = tmp.loc[tmp.index.get_level_values(-1) == omega]\n",
    "                if tmp.shape[0] > 1:\n",
    "                    tmp.index = tmp.index.droplevel(-1)\n",
    "                    sol_full_omega._solution[key] = tmp\n",
    "                else:\n",
    "                    sol_full_omega._solution[key] = tmp.iloc[0]\n",
    "            elif pftype in ['lpacc', 'lpacf', 'qpac'] and key in lpac_sol_keys:\n",
    "                tmp = sol_full_omega[key]\n",
    "                tmp = tmp.loc[tmp.index.get_level_values(-1) == omega]\n",
    "                if tmp.shape[0] > 1:\n",
    "                    tmp.index = tmp.index.droplevel(-1)\n",
    "                    sol_full_omega._solution[key] = tmp\n",
    "                else:\n",
    "                    sol_full_omega._solution[key] = tmp.iloc[0]\n",
    "            else:\n",
    "                sol_full_omega._solution.pop(key)\n",
    "        sol_full_omega.to_zip(sur_filename)\n",
    "\n",
    "    # if the contingency has not yet been validated under the ACOPF model\n",
    "    if not os.path.exists(val_filename):\n",
    "        if pftype in ['dc']:\n",
    "            update_md_inplace_dc(md, omega, sol_full, specs)\n",
    "        elif pftype in ['lpacc', 'lpacf', 'qpac']:\n",
    "            update_md_inplace_lpac(md, omega, sol_full, specs)\n",
    "        acopf, _ = create_psv_acopf_model(md, **kwargs)\n",
    "\n",
    "        acopf.del_component('obj')\n",
    "\n",
    "        @acopf.Objective(sense=minimize)\n",
    "        def obj(acopf):\n",
    "            p_load_shed_tot = sum(acopf.p_load_shed[d] for d in acopf.p_load_shed)\n",
    "            p_over_generation_tot = 1e3 * sum(acopf.p_over_generation[g] for g in acopf.p_over_generation)\n",
    "            q_over_generation_tot = 1e3 * sum(acopf.q_over_generation[g] for g in acopf.q_over_generation)\n",
    "            return p_load_shed_tot + p_over_generation_tot + q_over_generation_tot\n",
    "\n",
    "        @acopf.Constraint(acopf._var_pl_index_set)\n",
    "        def eq_shed_proportion(acopf, n):\n",
    "            if acopf.pl[n].value > 0:\n",
    "                return acopf.q_load_shed[n] == acopf.ql[n].value / acopf.pl[n].value * acopf.p_load_shed[n]\n",
    "            else:\n",
    "                return acopf.q_load_shed[n] == 0\n",
    "\n",
    "        for n in acopf.p_load_shed:\n",
    "            acopf.p_load_shed[n] = sum(md.data['elements']['load'][d]['p_load_shed']\n",
    "                                       for d in specs['D_n'].get(n, []))\n",
    "\n",
    "        solver = SolverFactory('ipopt')\n",
    "        result = solver.solve(acopf, tee=True)\n",
    "        PyomoSolution.from_solved_instance(acopf).to_zip(val_filename)\n",
    "\n",
    "    hashdict[omega] = hashtup\n",
    "    print(f, omega, hashtup)\n",
    "\n",
    "os.makedirs(os.path.join(ACPF_RESULTS_DIR, 'results'), exist_ok=True)\n",
    "jsonfilename = os.path.join(ACPF_RESULTS_DIR, 'results', f'{approach}-{casestudy}-{pftype}-f{f}-r{r_hat}.json')\n",
    "with open(jsonfilename, 'w') as fh:\n",
    "    json.dump(hashdict, fh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
