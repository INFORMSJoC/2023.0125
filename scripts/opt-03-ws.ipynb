{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54add744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import multiprocessing\n",
    "import os\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "from config import SPECS_COMPLETE_YAMLS, WS_RESULTS_DIR\n",
    "from model import DC, LPAC, Solution\n",
    "from util import Grid, ResilienceState, in_notebook, max_budget_by_omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d7676-028d-49cf-bb19-2812dad4ff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user inputs\n",
    "if in_notebook():\n",
    "    f_min = 0\n",
    "    f_max = 20\n",
    "    f_inc = 1\n",
    "    r_hat = 3\n",
    "    pftype = 'dc'\n",
    "    casestudy = 'imelda'\n",
    "    num_processes = 8\n",
    "else:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--fmin')\n",
    "    parser.add_argument('--fmax')\n",
    "    parser.add_argument('--finc')\n",
    "    parser.add_argument('--rhat')\n",
    "    parser.add_argument('--casestudy')\n",
    "    parser.add_argument('--pftype')\n",
    "    parser.add_argument('--numprocesses')\n",
    "    args = parser.parse_args()\n",
    "    f_min = int(args.fmin)\n",
    "    f_max = int(args.fmax)\n",
    "    f_inc = int(args.finc)\n",
    "    r_hat = int(args.rhat)\n",
    "    pftype = str(args.pftype)\n",
    "    casestudy = str(args.casestudy)\n",
    "    num_processes = int(args.numprocesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90fbf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_threads = multiprocessing.cpu_count()\n",
    "gurobi_threads = int(np.floor(hw_threads / num_processes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11429c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEGREE = 1\n",
    "WEIGHTS_LOAD = [1.000]\n",
    "WEIGHTS_FLOW = [0.000, 0.025, 0.050, 0.075, 0.100, 0.125, 0.150]\n",
    "OVERSPEND = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8b990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classes = {\n",
    "    'dc': DC,\n",
    "    'lpacc': LPAC,\n",
    "    'lpacf': LPAC,\n",
    "    'qpac': LPAC\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8aa9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "with open(SPECS_COMPLETE_YAMLS[casestudy, pftype]) as fh:\n",
    "    specs = yaml.load(fh, Loader=yaml.Loader)\n",
    "    for key, val in specs['r_hat'].items():\n",
    "        specs['r_hat'][key] = min(val, r_hat)\n",
    "    for key in list(specs['xi']):\n",
    "        (k, r, omega) = key\n",
    "        if r > r_hat:\n",
    "            specs['xi'].pop(key)\n",
    "    for k in specs['R']:\n",
    "        specs['R'][k] = [i for i in range(1, min(max(specs['R'][k]), r_hat) + 1)]\n",
    "specs['options']['approach'] = 'stochastic'  # arbitrary since there is only one scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3cd464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_wait_and_see(modelcls, omega, specs):\n",
    "    specs_copy = specs.copy()\n",
    "    f_req = max_budget_by_omega(**specs_copy)[omega]\n",
    "    probability = specs_copy.pop('probability')\n",
    "    Omega = specs_copy.pop('Omega')\n",
    "    xi = specs_copy.pop('xi')\n",
    "    specs_copy['Omega'] = {omega}\n",
    "    specs_copy['probability'] = {omega: 1.0}\n",
    "    specs_copy['xi'] = {(k, r, omega_prime): xi[k, r, omega]\n",
    "                        for (k, r, omega_prime) in xi\n",
    "                        if omega_prime == omega}\n",
    "    MODEL = modelcls(**specs_copy)\n",
    "    MODEL.model.setParam('MIPGap', 0.0)\n",
    "    MODEL.model.setParam('PreSolve', 2)\n",
    "    MODEL.model.setParam('OutputFlag', 0)\n",
    "    MODEL.model.setParam('Threads', gurobi_threads)\n",
    "    MODEL.model.setParam('MIPFocus', 2)\n",
    "    MODEL.model.setParam('ImpliedCuts', 2)\n",
    "    MODEL.model.setParam('ProjImpliedCuts', 2)\n",
    "\n",
    "    grid = Grid(specs_copy)\n",
    "    rstate = ResilienceState(grid)\n",
    "\n",
    "    for f in np.arange(f_min, min(f_max, f_req) + f_inc, f_inc):\n",
    "\n",
    "        MODEL.con_resource_hi.RHS = f\n",
    "        MODEL.update()\n",
    "\n",
    "        MODEL.model.NumStart = len(WEIGHTS_LOAD) * len(WEIGHTS_FLOW) + (1 if f > 0 else 0)\n",
    "        for i, (weight_load, weight_flow) in enumerate(product(WEIGHTS_LOAD, WEIGHTS_FLOW)):\n",
    "            rstate.reset()\n",
    "            sol = rstate.adopt_stochastic_greedy_solution(f, DEGREE, weight_load, weight_flow, OVERSPEND)\n",
    "            MODEL.model.setParam('StartNumber', i)\n",
    "            for (k, r) in MODEL.x:\n",
    "                MODEL.x[(k, r)].Start = 1 if (k, r) in sol else 0\n",
    "        if f > 0:\n",
    "            MODEL.model.setParam('StartNumber', i + 1)\n",
    "            last_zipfile = os.path.join(WS_RESULTS_DIR, f'{casestudy}-{pftype}-f{f-1}-omega{omega}-r{r_hat}.zip')\n",
    "            solution = Solution.from_zip(last_zipfile)\n",
    "            for key, val in solution['x'].items():\n",
    "                MODEL.x[key].Start = val\n",
    "        MODEL.update()\n",
    "\n",
    "        os.makedirs(WS_RESULTS_DIR, exist_ok=True)\n",
    "        zipfile = os.path.join(WS_RESULTS_DIR, f'{casestudy}-{pftype}-f{f}-omega{omega}-r{r_hat}.zip')\n",
    "        if not os.path.exists(zipfile):\n",
    "            print(omega, f)\n",
    "            MODEL.solve()\n",
    "            solution = Solution.from_solved_instance(MODEL)\n",
    "            solution.to_zip(zipfile, variables=['x', 'ObjVal', 'ObjBound', 'gamma', 'gamma_under', 'gamma_over'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a9b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [(model_classes[pftype], omega, specs)\n",
    "        for omega in specs['Omega'].copy()]\n",
    "\n",
    "with multiprocessing.Pool(num_processes) as pool:\n",
    "    pool.starmap(solve_wait_and_see, args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
